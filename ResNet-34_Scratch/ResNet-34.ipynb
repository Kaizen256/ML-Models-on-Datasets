{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa74bc15",
   "metadata": {},
   "source": [
    "# ResNet-34 From Scratch\n",
    "\n",
    "Using Tiny ImageNet, which contains 64×64 images instead of ImageNet’s standard 224×224.  \n",
    "Created a modified architecture by changing the first 7×7 convolution into a 3×3 convolution with padding so the height and width remain the same. Also removed the first MaxPool layer. \n",
    "\n",
    "I used Random cropping with padding, horizontal flipping and normalized with dataset-specific mean and std values computed in mean_std.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224518de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=(64,64), padding=4),         # slightly pad and then crop back to 64x64\n",
    "    transforms.RandomHorizontalFlip(),                      # randomly flip images left and right\n",
    "    transforms.ToTensor(),                                  # convert image to tensor\n",
    "    transforms.Normalize(mean=([0.4802, 0.4481, 0.3975]),   # normalize using mean & std\n",
    "                         std=([0.2296, 0.2263, 0.2255]))\n",
    "])\n",
    "\n",
    "data_dir = 'tiny-imagenet-200/train' # Train location on my laptop. The validation set is scrambled and it is really annoying to fix especially\n",
    "                                     # in Kaggle, so I split a validation set off the train set. I will run the saved model on the test data later.\n",
    "                                     \n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a5d7d",
   "metadata": {},
   "source": [
    "ResNet Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04845704",
   "metadata": {},
   "source": [
    "![Res_block](figures/resnet-block.png)\n",
    "\n",
    "***d2l.ai***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6a60d",
   "metadata": {},
   "source": [
    "Padding is fixed to 1 in ResNet Blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4697d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch:int, out_ch:int, stride:int):\n",
    "        super().__init__()\n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "        self.skip = nn.Identity()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.skip = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, stride=stride)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sequence(x)\n",
    "        x = self.skip(x)\n",
    "        return self.relu(x + out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ade26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetStack(nn.Module):\n",
    "    def __init__(self, in_ch:int, out_ch:int, stride:int, blocks:int):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock(in_ch, out_ch, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResNetBlock(out_ch, out_ch, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4f57c",
   "metadata": {},
   "source": [
    "| Layer         | Details                                                             | Output shape |\n",
    "| ------------- | ------------------------------------------------------------------- | ------------ |\n",
    "| **Input**     | 3×64×64                                                             | 64×64×3      |\n",
    "| **conv1**     | 3×3, stride=1, pad=1, 64 filters                                    | 64×64×64     |\n",
    "| **bn + relu** |                                                                     | 64×64×64     |\n",
    "| **conv2\\_x**  | 3 blocks: each <br> \\[3×3,64,s=1,p=1] + \\[3×3,64,s=1,p=1] + skip    | 64×64×64     |\n",
    "| **conv3\\_x**  | 4 blocks: first block has stride=2 (downsamples to 32×32), then s=1 | 32×32×128    |\n",
    "| **conv4\\_x**  | 6 blocks: first block has stride=2 (16×16), then s=1                | 16×16×256    |\n",
    "| **conv5\\_x**  | 3 blocks: first block has stride=2 (8×8), then s=1                  | 8×8×512      |\n",
    "| **avgpool**   | global avg pool                                                     | 1×1×512      |\n",
    "| **fc**        | linear 512→200                                                      | 200          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311eb5f4",
   "metadata": {},
   "source": [
    "| Block    | k | s | p | out channels | repeats | downsample  |\n",
    "| -------- | - | - | - | ------------ | ------- | ------------|\n",
    "| conv2\\_x | 3 | 1 | 1 | 64           | 3       | No          |\n",
    "| conv3\\_x | 3 | 2 | 1 | 128          | 4       | Yes         |\n",
    "| conv4\\_x | 3 | 2 | 1 | 256          | 6       | Yes         |\n",
    "| conv5\\_x | 3 | 2 | 1 | 512          | 3       | Yes         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b755094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2_x = ResNetStack(in_ch=64, out_ch=64, stride=1, blocks=3)\n",
    "        self.conv3_x = ResNetStack(in_ch=64, out_ch=128, stride=2, blocks=4)\n",
    "        self.conv4_x = ResNetStack(in_ch=128, out_ch=256, stride=2, blocks=6)\n",
    "        self.conv5_x = ResNetStack(in_ch=256, out_ch=512, stride=2, blocks=3)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.linear = nn.Linear(in_features=512, out_features=200)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0ebaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet34()\n",
    "\n",
    "X = torch.randn(1, 3, 64, 64)\n",
    "out = model(X)\n",
    "\n",
    "out.shape # Should be [1, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc46de0",
   "metadata": {},
   "source": [
    "| Parameter    | Value                                  |\n",
    "| ------------ | -------------------------------------- |\n",
    "| optimizer    | SGD + momentum=0.9                     |\n",
    "| lr           | 0.1 (step decay or cosine)             |\n",
    "| weight decay | 1e-4                                   |\n",
    "| batch size   | 128                                    |\n",
    "| epochs       | 80-100                                 |\n",
    "| augmentation | RandomCrop(64,4), RandomHorizontalFlip |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import json\n",
    "\n",
    "best_val_acc = 0.0\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"lr\": []\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = ResNet34().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0004)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(xb)\n",
    "        loss = loss_fn(yhat, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = torch.argmax(yhat, dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            yhat = model(xb)\n",
    "            loss = loss_fn(yhat, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "            preds = torch.argmax(yhat, dim=1)\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / val_total\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    history[\"train_loss\"].append(avg_loss)\n",
    "    history[\"train_acc\"].append(accuracy)\n",
    "    history[\"val_loss\"].append(avg_val_loss)\n",
    "    history[\"val_acc\"].append(val_accuracy)\n",
    "    history[\"lr\"].append(current_lr)\n",
    "\n",
    "    with open(\"training_history.json\", \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), \"ResNet34_best.pth\")\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
