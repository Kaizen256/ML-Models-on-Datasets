{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84cad4d",
   "metadata": {},
   "source": [
    "Implementing GoogLeNet(Inception v1) from scratch using Pytorch. Instead of using ImageNet, I use Tiny ImageNet which has 200 classes instead of 1000. Added BatchNorm (original GoogLeNet didn't) to help with generalization. Model will be trained in kaggle with a TPU VM v3-8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578ac17",
   "metadata": {},
   "source": [
    "Original architecture of GoogLeNet for a 224x224 image is as followed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1c8f5",
   "metadata": {},
   "source": [
    "![Old_Architecture](figures/Original_arch.png)\n",
    "\n",
    "***d2l.ai***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9433f",
   "metadata": {},
   "source": [
    "![Google_Architecture](figures/Google_arch.png)\n",
    "\n",
    "***GoogLeNet paper (Szegedy et al. 2015)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db68db",
   "metadata": {},
   "source": [
    "Tiny ImageNet uses 64×64 images, which are much smaller than the original ImageNet images (224×224). If we applied the original GoogLeNet architecture, repeated pooling and strides would reduce the spatial dimensions too quickly, causing significant loss of spatial information. To address this, I modified the initial layers and pooling strategy to slow down how quickly the spatial size shrinks. This preserves more local features throughout the network. The output channels after each block still match the original GoogLeNet design.\n",
    "\n",
    "I also drew out the architecture by hand to help visualize the tensor shapes. S1 means stride = 1, P1 means padding = 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843db7f",
   "metadata": {},
   "source": [
    "![Architecture](figures/New_arch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7430f4",
   "metadata": {},
   "source": [
    "Importing and loading the dataset which is stored on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='tiny-imagenet-200/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root='tiny-imagenet-200/val', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img, label = train_dataset[0]\n",
    "\n",
    "img = img.permute(1, 2, 0)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label index: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc702dd1",
   "metadata": {},
   "source": [
    "![Fish](figures/fish.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f9574",
   "metadata": {},
   "source": [
    "Creating the Inception Block class. The architecture of the Inception Block is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b72602",
   "metadata": {},
   "source": [
    "| Path  | Operation                                   |\n",
    "| ----- | ------------------------------------------- |\n",
    "| **1** | 1×1 conv → BN → ReLU                        |\n",
    "| **2** | 1×1 conv → BN → ReLU → 3×3 conv → BN → ReLU |\n",
    "| **3** | 1×1 conv → BN → ReLU → 5×5 conv → BN → ReLU |\n",
    "| **4** | 3×3 maxpool → 1×1 conv → BN → ReLU          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9095af",
   "metadata": {},
   "source": [
    "Output channels for each layer: \n",
    "| Block  | 1x1 | 1x1→3x3 | 3x3 | 1x1→5x5 | 5x5 | pool→1x1 | Total out |\n",
    "| ------ | --- | ------- | --- | ------- | --- | -------- | --------- |\n",
    "| **3a** | 64  | 96      | 128 | 16      | 32  | 32       | 256       |\n",
    "| **3b** | 128 | 128     | 192 | 32      | 96  | 64       | 480       |\n",
    "| **4a** | 192 | 96      | 208 | 16      | 48  | 64       | 512       |\n",
    "| **4b** | 160 | 112     | 224 | 24      | 64  | 64       | 512       |\n",
    "| **4c** | 128 | 128     | 256 | 24      | 64  | 64       | 512       |\n",
    "| **4d** | 112 | 144     | 288 | 32      | 64  | 64       | 528       |\n",
    "| **4e** | 256 | 160     | 320 | 32      | 128 | 128      | 832       |\n",
    "| **5a** | 256 | 160     | 320 | 32      | 128 | 128      | 832       |\n",
    "| **5b** | 384 | 192     | 384 | 48      | 128 | 128      | 1024      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a0d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, c1: int, c2: tuple, c3: tuple, c4: int):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.c1_out = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=c1, kernel_size=1),\n",
    "            nn.BatchNorm2d(c1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.c2_out = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=c2[0], kernel_size=1),\n",
    "            nn.BatchNorm2d(c2[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=c2[0], out_channels=c2[1], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(c2[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.c3_out = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=c3[0], kernel_size=1),\n",
    "            nn.BatchNorm2d(c3[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=c3[0], out_channels=c3[1], kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(c3[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.c4_out = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=c4, kernel_size=1),\n",
    "            nn.BatchNorm2d(c4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out1 = self.c1_out(X)\n",
    "        out2 = self.c2_out(X)\n",
    "        out3 = self.c3_out(X)\n",
    "        out4 = self.c4_out(X)\n",
    "        return torch.cat([out1, out2, out3, out4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.Inception3a = InceptionBlock(in_ch=192, c1=64, c2=(96, 128), c3=(16, 32), c4=32)   # Out Channels = 256\n",
    "        self.Inception3b = InceptionBlock(in_ch=256, c1=128, c2=(128, 192), c3=(32, 96), c4=64) # Out Channels = 480\n",
    "\n",
    "        self.MaxPool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # Shapes to 480x8x8\n",
    "\n",
    "        self.Inception4a = InceptionBlock(in_ch=480, c1=192, c2=(96, 208), c3=(16, 48), c4=64)    # Out Channels = 512\n",
    "        self.Inception4b = InceptionBlock(in_ch=512, c1=160, c2=(112, 224), c3=(24, 64), c4=64)   # Out Channels = 512\n",
    "        self.Inception4c = InceptionBlock(in_ch=512, c1=128, c2=(128, 256), c3=(24, 64), c4=64)   # Out Channels = 512\n",
    "        self.Inception4d = InceptionBlock(in_ch=512, c1=112, c2=(144, 288), c3=(32, 64), c4=64)   # Out Channels = 528\n",
    "        self.Inception4e = InceptionBlock(in_ch=528, c1=256, c2=(160, 320), c3=(32, 128), c4=128) # Out Channels = 832\n",
    "\n",
    "        self.MaxPool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # Shapes to 832x4x4\n",
    "\n",
    "        self.Inception5a = InceptionBlock(in_ch=832, c1=256, c2=(160, 320), c3=(32, 128), c4=128) # Out Channels = 832\n",
    "        self.Inception5b = InceptionBlock(in_ch=832, c1=384, c2=(192, 384), c3=(48, 128), c4=128) # Out Channels = 1024\n",
    "\n",
    "        self.GlobalPool = nn.AdaptiveAvgPool2d((1,1)) # 1024x1x1\n",
    "        self.Flatten = nn.Flatten(1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.Linear = nn.Linear(in_features=1024, out_features=200)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.Inception3a(x)\n",
    "        x = self.Inception3b(x)\n",
    "        x = self.MaxPool3(x)\n",
    "        x = self.Inception4a(x)\n",
    "        x = self.Inception4b(x)\n",
    "        x = self.Inception4c(x)\n",
    "        x = self.Inception4d(x)\n",
    "        x = self.Inception4e(x)\n",
    "        x = self.MaxPool4(x)\n",
    "        x = self.Inception5a(x)\n",
    "        x = self.Inception5b(x)\n",
    "        x = self.GlobalPool(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.Linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc4669",
   "metadata": {},
   "source": [
    "Testing to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GoogLeNet()\n",
    "\n",
    "X = torch.randn(1, 3, 64, 64)\n",
    "out = model(X)\n",
    "\n",
    "out.shape # Should be [1, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caa566",
   "metadata": {},
   "source": [
    "The original GoogLeNet was trained on ImageNet using Cross-Entropy Loss, SGD with momentum=0.9, learning rate = 0.01, weight decay = 0.0002, learning rate decay = 4% every 8 epochs (gamma=0.96 in StepLR), and was trained for 68 epochs.\n",
    "\n",
    "I’m following these hyperparameters but training for 94 epochs.\n",
    "\n",
    "The original model also used auxiliary classifiers, but I did not implement those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbaf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = GoogLeNet().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0002)\n",
    "scheduler = StepLR(optimizer, step_size=8, gamma=0.96)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(xb)\n",
    "        loss = loss_fn(yhat, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = torch.argmax(yhat, dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            yhat = model(xb)\n",
    "            loss = loss_fn(yhat, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "            preds = torch.argmax(yhat, dim=1)\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / val_total\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da401540",
   "metadata": {},
   "source": [
    "![Results](figures/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd883d2f",
   "metadata": {},
   "source": [
    "A Top-1 validation accuracy of around 50% is in line for a GoogLeNet made from scratch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
