{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0a5e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                                    object\n",
       "Age                                      float64\n",
       "City                                      object\n",
       "Working Professional or Student           object\n",
       "Profession                                object\n",
       "Academic Pressure                        float64\n",
       "Work Pressure                            float64\n",
       "CGPA                                     float64\n",
       "Study Satisfaction                       float64\n",
       "Job Satisfaction                         float64\n",
       "Sleep Duration                            object\n",
       "Dietary Habits                            object\n",
       "Degree                                    object\n",
       "Have you ever had suicidal thoughts ?     object\n",
       "Work/Study Hours                         float64\n",
       "Financial Stress                         float64\n",
       "Family History of Mental Illness          object\n",
       "Depression                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "train = pd.read_csv('train.csv')\n",
    "train.drop(['id', 'Name'], axis=1, inplace=True)\n",
    "train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79d849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs   = ['Age', 'Academic Pressure', 'Work Pressure',\n",
    "                 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']\n",
    "cat_attribs   = ['Gender', 'City', 'Working Professional or Student', 'Profession', 'Sleep Duration',\n",
    "                 'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\",  Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scale\",  StandardScaler())\n",
    "        ]), num_attribs),\n",
    "        (\"cat\",  Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_attribs)\n",
    "    ]\n",
    ")\n",
    "y = train['Depression']\n",
    "X = train.drop('Depression', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2665f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5),\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 62,\n",
    "        \"tree_method\": 'hist',\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    # Create pipeline with preprocessing + model\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessing\", preproc),\n",
    "        (\"xgb\", XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Use Stratified CV to preserve class balance\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=62)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Run the study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3702586",
   "metadata": {},
   "source": [
    "Trial 47 finished with value: 0.9397299218194741 and parameters: {'n_estimators': 529, 'max_depth': 3, 'learning_rate': 0.1420285246256477, 'subsample': 0.6617422555272853, 'colsample_bytree': 0.6053925503341293, 'gamma': 1.7799292133978808, 'reg_alpha': 2.5110255593175745, 'reg_lambda': 3.4353207613114574}. Best is trial 47 with value: 0.9397299218194741."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d353774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'n_estimators': 529, 'max_depth': 3, 'learning_rate': 0.1420285246256477, 'subsample': 0.6617422555272853, 'colsample_bytree': 0.6053925503341293, 'gamma': 1.7799292133978808, 'reg_alpha': 2.5110255593175745, 'reg_lambda': 3.4353207613114574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rowek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:42:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9396943852167733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print best result\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "# Build final pipeline using best params\n",
    "best_params = study.best_trial.params\n",
    "best_params.update({\n",
    "    \"use_label_encoder\": False,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"random_state\": 62\n",
    "})\n",
    "\n",
    "final_model = Pipeline([\n",
    "    (\"preprocessing\", preproc),\n",
    "    (\"xgb\", XGBClassifier(**best_params))\n",
    "])\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709e5c2",
   "metadata": {},
   "source": [
    "Test accuracy: 0.9396943852167733\n",
    "Train accuracy: 0.9397299218194741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2438ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004 Train Accuracy: 0.9394633972992181\n",
      "1004 Test accuracy: 0.9398720682302771\n",
      "--------------------------\n",
      "1005 Train Accuracy: 0.9394456289978678\n",
      "1005 Test accuracy: 0.9403340440653873\n",
      "--------------------------\n",
      "1006 Train Accuracy: 0.9397388059701492\n",
      "1006 Test accuracy: 0.940724946695096\n",
      "--------------------------\n",
      "1007 Train Accuracy: 0.9395167022032694\n",
      "1007 Test accuracy: 0.9404051172707889\n",
      "--------------------------\n",
      "1008 Train Accuracy: 0.9394278606965175\n",
      "1008 Test accuracy: 0.9395522388059702\n",
      "--------------------------\n",
      "1009 Train Accuracy: 0.9396055437100213\n",
      "1009 Test accuracy: 0.9395877754086709\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(17, 23):\n",
    "    params = {'n_estimators': 529, \n",
    "            'max_depth': 3, \n",
    "            'learning_rate': 0.1420285246256477, \n",
    "            'subsample': 0.6617422555272853, \n",
    "            'colsample_bytree': 0.6053925503341293, \n",
    "            'gamma': 1.7799292133978808, \n",
    "            'reg_alpha': 2.5110255593175745, \n",
    "            'reg_lambda': 3.4353207613114574,\n",
    "            'random_state': i + 987,\n",
    "            'n_jobs':-1,\n",
    "            \"eval_metric\": \"logloss\"\n",
    "            }\n",
    "\n",
    "    final_model = Pipeline([\n",
    "        (\"preprocessing\", preproc),\n",
    "        (\"xgb\", XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    print((i +987), \"Train Accuracy:\", np.mean(cross_val_score(final_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)))\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print((i +987), \"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.940724946695096\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 529, \n",
    "            'max_depth': 3, \n",
    "            'learning_rate': 0.1420285246256477, \n",
    "            'subsample': 0.6617422555272853, \n",
    "            'colsample_bytree': 0.6053925503341293, \n",
    "            'gamma': 1.7799292133978808, \n",
    "            'reg_alpha': 2.5110255593175745, \n",
    "            'reg_lambda': 3.4353207613114574,\n",
    "            'random_state': 1006,\n",
    "            'n_jobs':-1,\n",
    "            \"eval_metric\": \"logloss\"\n",
    "            }\n",
    "\n",
    "final_model = Pipeline([\n",
    "        (\"preprocessing\", preproc),\n",
    "        (\"xgb\", XGBClassifier(**params))\n",
    "])\n",
    "\n",
    "np.mean(cross_val_score(final_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "pred = final_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['Depression'] = pred\n",
    "sample.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3775cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.937366737739872\n",
      "Test accuracy: 0.9381307746979389\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "params = {\n",
    "    'iterations': 1766, \n",
    "    'learning_rate': 0.31965848232720384, \n",
    "    'depth': 3, 'l2_leaf_reg': 1.6093665037487805, \n",
    "    'bagging_temperature': 0.879762393824321, \n",
    "    'random_strength': 0.33996391481994964, \n",
    "    'border_count': 214,\n",
    "    'random_state': 62,\n",
    "    'task_type': 'CPU',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"preprocessing\", preproc),\n",
    "        (\"cat\", CatBoostClassifier(**params))\n",
    "    ])\n",
    "\n",
    "print(\"Train accuracy:\", np.mean(cross_val_score(cat_pipeline, X_train, y_train, cv=5, scoring='accuracy')))\n",
    "cat_pipeline.fit(X_train, y_train)\n",
    "y_pred = cat_pipeline.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf633f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat_pipeline.predict(test)\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['Depression'] = pred\n",
    "sample.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46921b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9392057569296375\n",
      "Test accuracy: 0.9403340440653873\n"
     ]
    }
   ],
   "source": [
    "Best_parameters = {'boosting_type': 'gbdt', \n",
    "                  'num_leaves': 26, \n",
    "                  'learning_rate': 0.25174389995069674, \n",
    "                  'feature_fraction': 0.5573841124238385, \n",
    "                  'bagging_fraction': 0.8452530741496862, \n",
    "                  'bagging_freq': 6, \n",
    "                  'min_child_samples': 5, \n",
    "                  'lambda_l1': 6.993044800464817, \n",
    "                  'lambda_l2': 0.7965595052137724,\n",
    "                  'random_state': 62,\n",
    "                  'num_threads':-1}\n",
    "from lightgbm import LGBMClassifier\n",
    "lg_pipeline = Pipeline([\n",
    "        (\"preprocessing\", preproc),\n",
    "        (\"lgb\", LGBMClassifier(**Best_parameters))\n",
    "    ])\n",
    "print(\"Train accuracy:\", np.mean(cross_val_score(lg_pipeline, X_train, y_train, cv=5, scoring='accuracy')))\n",
    "lg_pipeline.fit(X_train, y_train)\n",
    "y_pred = lg_pipeline.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f57ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lg_pipeline.predict(test)\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['Depression'] = pred\n",
    "sample.to_csv('submission4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
